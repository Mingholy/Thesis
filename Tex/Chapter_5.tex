\chapter{结合字词向量的命名实体识别}
\section{基于字词向量结合的特征嵌入与训练}
\subsection{嵌入粒度对命名实体识别的影响}
\label{subsec:analyze}
现有的命名实体识别方法一般基于两个思路，一是以不定长的词为粒度，依赖词性、上下文等特征，对特定的一些词序列进行标注或聚合（分块），最终得到与原文对应的标签序列；二是以字为粒度，依赖字本身的特征进行字符序列的标注。

思路一常见于以传统的基于统计的方法进行的命名实体识别中。
但该方法在实际应用中存在一定缺陷。
首先，基于词粒度的命名实体识别较为依赖分词的结果、词性等先验特征，分词结果的好坏与词性标注的结果将对命名实体识别的结果产生较大的影响；
其次，分词这一任务本身是识别语料中单独成词的序列，而命名实体中存在大量多个词组合而成复合实体，虽然分词的目的并不在于确定命名实体的词边界，但错误的分词结果将会消除命名实体的词边界，在此基础上识别的命名实体必然是错误的；
最后，即便分词结果相对可靠，但由于命名实体本身的结构是多变的，相同的词并不一定总是命名实体，而在训练语料中未被单独分出的词在测试语料中是命名实体，或者测试语料中是命名实体的序列根本未在训练语料中出现过，并且其也并不由训练语料中的某个或某些词组成，那么这样的命名实体就很难被识别出来。

其原因在于，在进行命名实体识别时，忽略了构成词的字的特征，如“梁孝王刘武……”，由于该序列中存在四个常见的人名姓氏，因此不论是直接分词，还是以姓氏字典作为触发字的识别，在这种情况下都会受到严重干扰，导致最终结果不正确。

总之，本文认为基于词的命名实体识别方法仅在语料规律相对明显，内容相对较为简单，且具备大规模的、成熟的人名、地名和机构名词典或特殊领域知识的情况下，有机会取得很好的效果。
但在处理未登录词问题上，还存在较大缺陷。而这里我们尚且仅考虑人名、地名和机构名，并未考虑其他特殊专名、网络新词与领域新词等其他命名实体，因为就命名实体识别而言，存在周期相对较短的部分新词并不作为该任务的关注重点。
以词作为基本单位进行命名实体识别，在一定程度上已经退化为短文本分类问题。

思路二是常见于基于神经网络的方法。考虑到以词为基本元素的命名实体识别存在较大难度，本文在对中医症状术语识别时就采用了基于字的方法。
虽然以字为基本元素进行端到端的命名实体识别时能够取得不错的效果，但其也存在一些问题。
首先，以字符为粒度对语料进行切分，会产生一些过长的字符序列。尽管LSTM在理论上能够接受任意长度的输入序列，但过长的序列会产生层数非常深的LSTM网络，这将使得网络参数量大大增加，训练速度相应降低。
其次，尽管LSTM具有一定的获取长距离上下文语义信息的能力，但若不对时间步的最大值加以限制，BPTT算法在进行误差的反向传播时，还是会面临严重的梯度消失问题，使得模型训练的结果变差。
最后，在神经网络模型中，字的表示来源于根据训练语料获得的字向量或通过大规模未标注语料预训练的字向量。
其信息往往不能完全覆盖预测环境下的语义，部分非命名实体的常用字可能也经常出现在命名实体中，而部分非命名实体中的罕用字由于缺乏训练语料的语义信息，往往多被判别为命名实体。

对于序列过长及其导致的梯度消失问题，可行的解决办法包括通过去除停用字、词控制序列长度，制定截断策略在设定的阈值前后切分长序列和对原序列进行采样等方法。本文中所使用训练语料大多不超过250字符，故在以字为基本单位时，序列长度设定不超过250。

\begin{table}[H]
    \centering
    \bicaption{基于字的识别部分伪正类和伪负类}{False negative and false positive examples of char-embedding recognition}
    \begin{tabular}{cccc}
        \toprule
        \multicolumn{2}{c}{False positive} & \multicolumn{2}{c}{False negative}\\
        \midrule
        错识别标签 & 字串 & 未识别标签 & 字串\\
        \cmidrule(lr){1-2}\cmidrule(lr){3-4}
        \multirow{3}{*}{PERSON} & 钟声 & \multirow{3}{*}{PERSON} & 安南 \\
        & 唐诗 & & 简 \\
        & 宋词 & & 老舍\\
        \cmidrule(lr){1-2}\cmidrule(lr){3-4}
        \multirow{2}{*}{LOC} & 苏东坡 & \multirow{2}{*}{LOC}& 梁园\\
        & 关牧村 & & 孟买 \\
        \cmidrule(lr){1-2}\cmidrule(lr){3-4}
        \multirow{2}{*}{ORG} & 复印社 & \multirow{2}{*}{ORG}& 国家银行\\
        & 台湾公司 & & 联合国\\
        \bottomrule
    \end{tabular}
    \label{tab:fp_fn_word}
\end{table}
而对于同字异义、异字同义等问题，这些往往来源于歧义。这一部分目前较难从根本上得到解决。

基于上述分析，本文提出一种在模型训练中结合字词向量的方法。该方法能够在降低分词效果对命名实体识别准确率的影响的同时，尽量减少无关的非命名实体的干扰，缩短序列长度，从而在较少影响精度的前提下，大幅提高模型训练效率。
\subsection{字向量结合的嵌入和训练}
\label{subsec:combine_word_char}
结合字词向量获得预训练词嵌入与模型的基本思路是，首先对原始语料进行粗切分并进行词性标注，然后取其中所有一级标签为名词词性的单词（包括人名、地名、机构名、一般名词、特殊专名等）切分成单字，保留动词、代词等其他词性的单词。
得到的粗分结果和词性标签，词性标签将作为对名词等进一步切分时的依据。
对预训练向量首先进行全文切分成字，训练字向量；然后对原始语料粗切分为词，训练词向量。最终构建的字词嵌入包含所有字向量和去除单字后的词向量。


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{wcframe}
    \bicaption{结合字词向量进行命名实体识别的总体流程}{Recognition procedures combining char and word embeddings}
    \label{fig:exp_frame}
\end{figure}

总体流程可如图\ref{fig:exp_frame}所示。
训练时，切分以熟语料标注结果为准；测试数据的预处理可使用jieba、HanLP\citep{hanlp}等开源语言处理工具进行处理。需要指出的是，为了减少词性标注中包含的命名实体识别结果，使用分词器进行分词时全部禁用了命名实体识别，并不使用任何附加的命名实体识别词典和领域知识。

本章实验以名词为切分目标，也可根据实际情况，灵活选择需要切分的词性对象。

\section{实验设计与数据预处理}
本章实验包括三个部分。首先，先采用第四章介绍的双向LSTM-CRF序列标注框架，建立使用字向量作为训练数据的的命名实体模型，并在这一部分考察使用不同LSTM实现对公开领域语料命名实体识别的效果。
其次，选取在第一部分表现较好的实现作为作为基线实验，并作为进一步的实验框架，增加词向量和结合字词向量作为训练数据的实验组，调整模型参数。
最后，对比不同模型在有无词性特征情况下进行命名实体识别的效果，分析词性特征对模型的影响。


实验数据的准备包含两部分：字词向量嵌入和训练语料预处理。字词向量的嵌入采用中文维基百科语料库，总大小约1.5G。使用Word2Vector的实现之一Gensim进行字词向量的训练。
其中，对字进行训练是针对命名实体，可能包含较多不常用字，因此字向量的获取采用Hierachical Softmax模型，上下文窗口设置为5，采样率为$10^-4$，最小词频设置为1，获取所有字的嵌入。
对词向量的训练针对常见词，模型采用Negative Sampling，最小词频设置为5，过滤掉罕见词。
最终获取的词向量为300维，其中字向量22884个，词向量544568个。
训练语料来源于人民日报，包含1998年1至6月经人工标注的语料，以其中一月数据作为测试集，其他数据作为训练集，进行开放测试。

原始语料格式如下：

\begin{verbatim}
本报/r  哈尔滨/ns  １月/t  １日/t  电/n  记者/n  董/nr  伟/nr
报道/v  ：/w  顶/v  着/u  寒风/n  ，/w  黑龙江省/ns  各级/r
领导/n  组成/v  若干/m  慰问/vn  小组/n  ，/w  在/p  节日/n
期间/f  深入/v  到/v  厂矿/j  车间/n  ，/w  为/p  困难/a  职工/n
送/v  去/v  党/n  的/u  温暖/an  。/w
\end{verbatim}

预处理过程中根据已经标注好的词性，按照节\ref{subsec:combine_word_char}思路进行如下处理：
\begin{enumerate}[leftmargin=*]
    \item 去除特殊符号、空标注等非法字符
    \item 去除l、i等与本文任务无关的组合词标签
    \item 合并组合命名实体，根据词性标签nr, ns, nt分别标注命名实体及其组成元素。标注模式如\ref{tab:label_schema}所示
    \item 合并所有名词类词性标签，去除人名、地名、机构名的二级类别标签，全部用一级类别n取代，并统一其他词性标签
    \item 分别生成字、词和字词结合的训练语料与测试语料
    \item 去除所有词性标签，作为对比实验语料
\end{enumerate}

对人民日报原始语料进行实体标签标注时采用BIO模式，标签设置如下表所示。

\begin{table}[H]
    \centering
    \bicaption{标注模式}{Label schema}
    \begin{tabular}{ll}
        \toprule
        \multicolumn{2}{c}{BIO标签集}\\
        \midrule
        B-PER & 人名起始及单字（词）人名 \\
        I-PER & 人名中间字词 \\
        B-LOC & 地名起始及单词地名 \\
        I-LOC & 地名中间字词 \\
        B-ORG & 机构名起始及单词机构名 \\
        I-ORG & 机构名中间字词 \\
        O & 非命名实体\\
        \bottomrule
    \end{tabular}
    \label{tab:label_schema}
\end{table}

实验平台基于Ubuntu 16.04LTS，CPU为Intel I5 8600K CPU，GPU 为nVidia GeForce GTX 1070Ti，内存为16G。双向LSTM-CRF序列标注框架的实现基于TensorFlow-GPU 1.6.0，Python版本为3.5。
所有实验均使用GPU加速，CUDA版本为8.0, cuDNN版本为7.0。

模型的超参数设置如下：
\begin{table}[H]
    \centering
    \bicaption{参数列表}{Parameters list}
    \begin{tabular}{ll}
        \toprule
        \multicolumn{2}{c}{模型超参数设置} \\
        \midrule
        batch\_size & 512（字嵌入）/800（词嵌入） \\
        隐藏层单元数量 & 256\\
        全局drop\_out\_rate & 0.5 \\
        l2正则化参数 & 0.01 \\
        初始学习率 & 0.002 \\
        早停等待epoch数 & 3\\
        序列最大长度 & 250（字嵌入）/120（词嵌入）\\
        \bottomrule
    \end{tabular}
\end{table}
其中，batch\_size由于显存限制，最大设置为表中数值；实际选择结果最优的参数重复实验。训练集与验证集的比例为9:1。

\section{实验结果与分析}
与章节\ref{sec:tcm-pfr}中提到的评价标准不同的是，本节数据来源于公共领域数据集，对人名、地名和机构名的界定相较中医症状术语而言更为明确，且语料本身质量较高，能够明确地确定单个实体。
故本节以整个命名实体识别结果作为评价对象。模型识别结果与实际结果完全一致则可归为正类，否则即为负类。具体表示为：
\begin{align}
    Precision &= \frac{True Positive}{Predict Size} \times 100\% \\
    Recall &= \frac{True Positive}{Entity Size} \times 100\% \\
    F-measure &= \frac{2\times Precision \times Recall}{Precision + Recall}
\end{align}
其中$True Positive$指完全识别正确的实体数，$Predict Size$指模型识别结果包含的实体数，$Entity Size$指实际存在的实体数。

需要指出的是，本文进行实验数据情况与文献\citepns{吴友政2006汉语问答系统关键技术研究}中的情况类似。
本文考虑到人民日报语料本身的性质，其中存在大量命名实体，其内容和出现的上下文在整个语料集中具有较好的一致性，故可能与其他语料存在一定差异，特此提出。
但这并不影响方法效果的对比。

首先，在只以字嵌入作为特征的情况下，对比不同LSTM实现下，命名实体识别结果的差异。
\begin{table}[H]
    \centering
    \bicaption{实验一：以字嵌入作为特征}{Experiment 1: char-embedding}
    \small
    \begin{tabular}{cccccccccc}
        \toprule
            \multirow{2}{*}{Cell} &\multicolumn{3}{c}{PERSON} &\multicolumn{3}{c}{LOC} &\multicolumn{3}{c}{ORG}\\
            \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
            & P & R & F1 & P & R & F1 & P & R & F1\\
        \midrule
        LSTM(baseline) & 93.51 & 90.27 & 91.86 & 90.44 & 88,66 & 89.54 & 86.99 & 89.16 & 88.07\\
        LSTM(peep-hole) & 93.94 & 90.56 & 92.22 & 90.99 & 89.63 & 90.31 & 87.68 & 89.35 & 88.51\\
        GRU & 93.61 & 90.31 & 91.93 & 90.73 & 90.54 & 90.64 & 87.48 & 89.49 & 88.48\\
        CIFG  & 93.19 & 90.28 & 91.71 & 90.72 & 88.84 & 89.76 & 87.03 & 88.82 & 87.91\\
        \bottomrule
    \end{tabular}
    \label{tab:lstm_cell_comparison}
\end{table}

实验数据表明，在仅使用字特征的情况下，在该语料环境下不同LSTM实现对结果影响较为微小。
后续实验选择GRU作为LSTM cell实现进行。

\begin{table}[H]
    \centering
    \bicaption{实验二：字嵌入与词性特征}{Experiment 2: char-embedding and POS features}
    \begin{tabular}{cccc}
        \toprule
        & & char+pos & char\\
        \midrule
        \multirow{3}{*}{PER} & P & 94.20 & 93.61\\
        & R & 92.17 & 90.31\\
        & F & 93.18 & 91.93 \\
        \midrule
        \multirow{3}{*}{LOC} & P & 91.76 & 90.73\\
        & R & 91.69 & 90.54 \\
        & F & 91.73 & 90.64\\
        \midrule
        \multirow{3}{*}{ORG} & P & 88.77 & 87.48\\
        & R & 90.73 & 89.49\\
        & F & 91.85 & 88.48\\
        \midrule
        \multirow{3}{*}{Overall} & P & 92.02 & 91.09\\
        & R & 91.67 & 90.23\\
        & F & 91.85 & 90.66\\
        \bottomrule
    \end{tabular}
    \label{tab:char-comparison}
\end{table}
基于字嵌入的命名实体识别结果表明，字嵌入能够很好地获取上下文信息。
并且由于识别效果已经很好，词性特征虽然对识别结果有一定提升，但整体不会有更大的改观。
本文认为在基于字嵌入的模型中，词性在一定程度上帮助了模型确定词边界。
由于词性、分词结果是共同产生的，字嵌入消除了分词结果带来的负面影响，但难以消除词性标注错误对识别结果的影响，使得词性的作用存在两面性。

\begin{table}[H]
    \centering
    \bicaption{实验三：词嵌入与词性特征}{Experiment 3: word-embedding and POS features}
    \begin{tabular}{cccc}
        \toprule
        & & word+pos & word\\
        \midrule
        \multirow{3}{*}{PER} & P & 55.31 & 55.18\\
        & R & 27.01 & 29.81\\
        & F & 36.29 & 38.72 \\
        \midrule
        \multirow{3}{*}{LOC} & P & 89.41 & 90.76\\
        & R & 84.72 & 84.39 \\
        & F & 87.00 & 87.46\\
        \midrule
        \multirow{3}{*}{ORG} & P & 86.58 & 88.08\\
        & R & 43.71 & 41.65\\
        & F & 58.09 & 56.56\\
        \midrule
        \multirow{3}{*}{Overall} & P & 78.91 & 79.94\\
        & R & 54.73 & 55.22\\
        & F & 64.97  & 65.33\\
        \bottomrule
    \end{tabular}
    \label{tab:word-comparison}
\end{table}

由表\ref{tab:word-comparison}可见，词嵌入与基于神经网络的序列标注框架的适应性很差，分词的结果与标注模式相差较大，导致命名实体识别的准确率、召回率都很低，这表明在真实条件下依赖分词结果进行命名实体识别可行性较低。

其分词标注如果与训练模型的标注标准不统一，会在嵌入和训练两个阶段导致命名实体识别效果低下：
一是分词结果若在预训练向量中未出现，则模型将在预测时随机初始化嵌入向量，将该词作为未登录词处理。这样就难以利用组成该词的字向量进行识别。
二是若作为未登录词输入模型，则模型将词所在上下文对其标签进行预测。若分词结果不一致，其上下文必然存在较大差异。而在同样以词为基本单位的训练数据中，更难存在上下文类似的训练场景。
这导致第一阶段造成的影响进一步被放大，最终效果很不理想。

通过对比人名、地名和机构名的识别结果可以发现，这在人名识别上体现得较为明显，因为人名一般较短，且多数人名（此处的多数是指语料中出现次数较多，而非以此为名的人数）并不包含能够独立成词的字序列，故分词系统倾向将无法切分的人名视作一个整体。
而训练语料中将人名分为姓和名，就造成了难以识别的结果。
而对地名、组织机构名的识别则相对较好，本文认为原因在于地名、机构名中包含较多可单独成词的字序列，在被切分后进行序列标注过程中，仍然可以较好地识别。
因此分词对人名识别结果的影响要大于地名、机构名。

在基于词嵌入的命名实体识别错误的结果中，主要存在下列几类错误：
\begin{enumerate}[leftmargin=*]
    \item 由于姓氏、名字切分导致的识别不完整，如\verb|宋学斌|，由于错误地切分为\verb|宋学|和\verb|斌|而未能识别。
    \item 由于词性歧义产生的识别错误，如人名\verb|严明|也做形容词在训练语料中出现。
    \item 由缩写、别称导致的不能在预训练的词嵌入中获取原始特征导致的识别失败，如\verb|日外交部|，\verb|英国PPL|等。
\end{enumerate}

\begin{table}[H]
    \centering
    \bicaption{实验四：字词向量结合的命名实体识别}{Experiment 4: char and word embeddings recognition results}
    \begin{tabular}{cccc}
        \toprule
        && char\&word & char\&word+pos\\
        \midrule
        \multirow{3}{*}{PER} & P & 94.32 & 79.05\\
        & R & 92.61 & 70.45\\
        & F & 93.46 & 74.50 \\
        \midrule
        \multirow{3}{*}{LOC} & P & 91.49 & 84.44\\
        & R & 91.76 & 92.07 \\
        & F & 91.63 & 88.09\\
        \midrule
        \multirow{3}{*}{ORG} & P & 87.27 & 85.48\\
        & R & 84.85 & 86.20\\
        & F & 86.04 & 85.84\\
        \midrule
        \multirow{3}{*}{Overall} & P & 91.69 & 82.87\\
        & R & 90.66 & 82.79\\
        & F & 91.17  & 82.83\\
        \bottomrule
    \end{tabular}
    \label{tab:word_char_comparison}
\end{table}
在不使用词性特征时，基于字词向量结合相比仅使用字向量，识别结果相差不多，在部分指标上略有提升。
在使用词性特征时，结果没有提升，反而在人名、地名上均有较大下降。本文认为引入词性后，词性特征强化了分词错误，与词嵌入类似，人名识别受到了很大干扰。

基于字词向量结合命名实体识别存在的错误也包括：
\begin{enumerate}[leftmargin=*]
    \item 词边界难以确定，如
        \begin{center}
            \verb|维也纳多瑙河/LOC 畔的联合国城|
        \end{center}
        被标注为
        \begin{center}
            \verb|维也纳/LOC 多瑙/LOC 河畔的联合国城|
        \end{center}
        这种情况同样也存在于较长的音译人名，如
        \begin{center}
            \verb|威廉·埃沃特·格兰德斯通|
        \end{center}
        应整体为人名，而模型将其标注为
        \begin{center}
            \verb|威廉|、\verb|埃沃特|、\verb|格兰德斯通|
        \end{center}
        导致人名识别准确率降低。
    \item 人名、地名和组织结构名的混淆，如“苏维埃”、“马尼拉”等。音译人名与地名，在字符特征而言并没有本质上的差别，因此这类错误只能根据上下文信息修正，说明模型在识别此类实体时还存在一定困难。
    \item 人名前后常见字对识别的影响，如“等”经常出现在一些人名之后，模型也倾向将其视为人名常用字。另外包括“老”、“小”等。
\end{enumerate}

\begin{table}[H]
    \centering
    \bicaption{多粒度嵌入和词性特征综合对比}{Multi granularity embeddings and POS feature comparison}
    \begin{tabular}{cccccccc}
        \toprule
        嵌入粒度 & P  & R  & F1 & 嵌入粒度 & P & R & F1\\
        \midrule
        char & 92.03 & 90.28 & 91.84 & char+pos & 92.02 &  91.67 & 91.85\\
        word & 79.94 & 55.22 & 65.33 & word+pos & 78.91 & 54.73 & 64.97\\
        word\&char & 91.68 & 90.66 & 91.17 & word\&char+pos & 82.87 & 82.79 & 82.83\\
        \bottomrule
    \end{tabular}
    \label{tab:overall_comparison}
\end{table}


最后，本文认为模型训练效率也是一个考察方法性能的重要指标。在实验过程中，我们记录了各次实验中训练模型所需的时间，按照模型嵌入粒度、是否使用词性特征两个维度分别对训练模型的平均时间进行对比，结果如表\ref{tab:train_time}所示。

\begin{table}[H]
    \centering
    \bicaption{各模型训练耗时对比}{Time consumption of models' training process}
    \begin{tabular}{ccc}
        \toprule
        嵌入粒度 & \multicolumn{2}{c}{消耗时间(s)}\\
        \midrule
        char  & 11842\\
        char+pos & 10433\\
        word  & 2703 \\
        word+pos  & 2384\\
        word\&char  & 5993\\
        word\&char+pos  & 5117 \\
        \bottomrule
    \end{tabular}
    \label{tab:train_time}
\end{table}

通过结果可以看出，字向量的平均训练时间都在1000s以上，单个epoch训练时间在210s左右，实际训练过程中单个模型训练epoch在30以上时，验证集上的损失才能收敛；这时batch-size已经设置为显存能够允许的最大值。这在一定程度上验证了节\ref{subsec:analyze}对字嵌入训练模型的缺点的分析，由于此时粒度细，输入序列相应变长，导致模型参数量和计算量大大增加，训练耗时也增加不少。
这在更大规模的数据集上会更加明显。
由于字符级别输入序列过长，LSTM深度在200以上，误差传播到较早时间步上时已经出现梯度消失的情况，导致每个epoch结束时计算验证集上的损失都非常接近，即模型在局部最优点附近震荡。即使将batch-size尽可能设置为较大值，其收敛速度也很慢。

相对而言词向量与字词向量结合能够节省更多的时间。但词向量在该模型下识别效果很差，而字词向量结合试图寻找二者之间的平衡点，取得了相对不错的平衡性。

综合比较下，字词向量结合的训练方法能够在不损失很多精度的同时，提升模型训练效率，在不使用词性特征的情况下，在部分实验指标中达到了与字向量结果相近的结果，在公共语料库上进行命名实体识别可采用字词嵌入结合的方法对语料进行处理，降低模型训练代价，具有一定实际应用价值。

\section{本章小结}
本章在传统基于字、词粒度进行命名实体识别的基础上，考察了命名实体识别错误发生的特点，提出了融合两种粒度对字词嵌入进行混合的思路，并基于此思路对标注框架中预训练词向量与训练、测试数据进行预处理。在此基础上，对比了多粒度训练的模型在不同LSTM实现上的效果。同时，还针对词性特征对命名实体识别结果的影响，对比了不同粒度嵌入下有无词性特征的识别效果。

本章针对预训练词向量和训练、测试语料处理这一环节，提出了可行的整合字词向量的思路，并在实际应用中取得了一定的效果。
