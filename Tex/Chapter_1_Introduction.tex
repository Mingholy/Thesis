\chapter{绪论}
\label{chap:introduction}
\section{课题背景及意义}
自然语言处理（Natrual Language Processing, NLP)是人工智能研究的一个重要组成部分，其研究内容和方法涉及到包括语言（音）学、计算机科学、数学和认知科学等在内的众多学科，其研究目的在于借助计算机处理、加工人类特有的自然语言信息，乃至生成人类可接受的语言文字信息，实现人机智能交互系统的构建。
早期的自然语言处理研究受限于当时认知科学水平和形式化理论的思潮，在发展的过程中摇摆于理性主义和经验主义之间。
20世纪90年代以来，计算机和网络大规模普及，硬件技术和性能指标都有了极大的提升，这为自然语言处理理论方法的研究提供了良好的契机；
同时，日益丰富的语言文字资源也为自然语言处理技术的发展带来了巨大的驱动力。

目前，自然语言处理的研究和应用所涉及的方向包括但不限于以下几个领域：信息检索、机器翻译、自动文摘、文本分类、问答系统、信息抽取、文本挖掘和语音识别与合成等。
在当前互联网产生的信息爆炸式增长的环境下，在海量信息中获取有价值信息已经成为数据科学的主要研究内容。
自然语言处理正是应对此类问题的有效技术，它在社会生产生活中的应用场景也越来越多样化，其核心技术在完成当前纷繁复杂的自然语言信息处理任务时，也面临着来自性能、效率和成本的挑战。
因此，利用机器学习、深度学习等方法，依托海量的语音、文本数据资源，在低人工干预、时间成本可控的前提下，高效、精确地解决自然语言处理问题，成为当前学术与工业界共同的研究热点。

以数据库存储为主要形式的结构化数据中包含大量由特定对象产生的、存在显著关系的信息，这一部分信息由于具有相对稳定的结构和实体关系，故成为前人进行数据挖掘研究的主要对象。
然而，经过了几十年的发展，互联网上包括自然语言在内的非结构化数据，远远多于结构化数据，并且其总量正在高速增长。这些数据具有数据形式多样、语义内容隐藏和处理手段复杂等特点。
我们可以发现，当前环境下非结构化文本具有如下特点：
\begin{enumerate}[\indent(1)]
    \item 数据体量巨大：在“用户产生内容”这一流行互联网运行模式的作用下，非结构化文本具有近乎“无限”的数据量。
    \item 难以提取有价值信息：文本结构复杂、语义特征隐晦、语言习惯繁多等等因素，给自然语言理解任务带来了众多挑战。
\end{enumerate}
而自然语言文本往往是非结构化的、实体和关系是混杂的，并且海量的数据往往包含大量的无用信息。如何从大量的原始数据中剔除噪声，获取其中有用的信息，就是自然语言处理需要解决的一个重要问题：信息抽取。
信息抽取需要从文本中获取用户感兴趣的知识内容，这些知识内容由文本中的特定元素构建，表现形式一般为事件或事实消息。
以新闻报道为例，文本中的特定元素即实体，包括时间、地点、人物、事件、原因、过程等。要获取这类信息，首先需要将这些内容从原始文本中辨别出来，再获取它们之间的关系，最终构建成为知识条目，作为提取的信息输出。

事实上，中文自然语言处理的大部分应用都面临着中文分词、词性标注、命名实体识别这类问题，我们称之为序列标注问题，即对观测到的文本序列元素，给出其对应的标签，以实现分词或标注。
解决这些问题往往是进行如信息抽取这类任务之前的基础，它们的结果往往对后续任务的效果有着重大的影响。

\section{国内外研究现状}
\label{sec:current}
\subsection{命名实体识别方法的研究现状}
命名实体识别是自然语言处理中序列标注问题的几项基本任务之一。
命名实体识别这一术语是于1995年的MUC-6(6th Message Understanding Conference)中首次使用的。当时的主要任务是从非结构化文本中抽取有价值的结构化信息，如人名、地名、组织机构名等。
早期的命名实体识别系统大多基于规则，由于其识别效果严重依赖人工制定的规则，实现成本过高且移植性差，故该方法逐渐被淘汰。
与此同时，对于命名实体的分类也从最开始的人名、地名、组织机构名这些基本大类，分别细化为各个小类。
经过若干次扩充范围与划分，2007年时命名实体的类别总数已有200余种。
自20世纪90年代以来，机器学习方法崭露头角，它们在众多领域大显身手，包括计算机图像处理、语音识别、人工智能等。在自然语言处理领域，基于大规模语料库的统计方法已经成为主流，这使得中、西文自然语言处理在数学意义上产生了一定的重合。
机器学习算法也被迅速地应用于命名实体识别这个具体的任务上。
一些经典的有监督学习模型和方法包括：
\begin{enumerate}[\indent(1)]
    \item 隐马尔科夫模型(Hidden Markov Model, HMM)
    \item 最大熵隐马尔科夫模型(Maximum-entropy Markov Model, MEMM)
    \item 支持向量机(Support Vector Machine, SVM)
    \item 条件随机场(Conditional Random Field, CRF)
    \item 决策树(Decision Tree)
\end{enumerate}
除此之外，还有一些弱监督、无监督和混合方法也应用于该任务上。
其中，\citet{bikel1997nymble}将HMM应用于英文和西班牙文的命名实体识别任务上，并在MUC-6数据集上取得了F值90\%以上的成果。
\citet{liu2005product}将层次隐马尔科夫模型应用于中文商品中的命名实体识别，抽取其中的产品品牌、类别和型号命名实体，并在数码产品和移动电话两个领域的数据集上的开放测试中分别获得了F值70\%和75\%以上的成果。

Mikheev\citep{mikheev1998description}在1998年提出了将最大熵模型与隐马尔可夫模型结合，在MUC-7命名实体识别任务上F值达到了93.39\%，是当时的最好成绩。
\citet{tsai2004mencius}则将领域知识规则和匹配模板融合今了最大熵模型，在MET-2语料上的实验显示，该模型对人名、地名和机构名的识别结果F值分别达到了94.3\%、77.8\%、75.3\%。

Asahara和Matsumoto\citep{asahara2003japanese}在2004年提出了一个基于字符特征的日文文本分块方法，利用该方法将文本分块并标注词性，最后引入支持向量机方法来在分块后的文本中找出潜在的命名实体，并在IREX NE任务中取得了F值87.2\%的结果。

McCallum和Li\citep{mccallum2003early}于2003年首次将条件随机场方法应用于命名实体识别任务上，在CoNLL-2003命名实体识别任务中英文识别F值达到了84.04\%。
由于CRF对比传统的基于规则的方法实现简便，效果不俗，此后在自然语言处理领域尤其是与序列标注问题相关的方向上得到了广泛的关注。
2005年\citet{finkel2005incorporating}的工作具有前瞻性地考虑到了序列标注任务中长程依赖的重要性，他们的工作在特征层引入了Gibbs采样来获取长程依赖，在解码层则使用模拟退火算法代替CRF中常见的Viterbi算法来求取最优的标注序列。在CoNLL-2003数据集上的实验显示，使用该方法改进的CRF模型的综合F值达到了86.86\%，相比只考虑较短窗口内特征、使用Viterbi算法的CRF模型其综合F值提升了1.35\%。

属于机器学习经典方法的决策树也在被\citet{sekine1998decision}尝试用来解决命名实体识别问题。该方法着重考虑了词边界的确定，综合了词性、字型和字典信息来给出每一个字符对应的标签概率，最后通过Viterbi算法获得最优的标注序列。

上述提到的方法主要是有监督的机器学习方法。另外的一些弱监督、无监督的学习方法与本文拟讨论的方法存在较大差异，且考虑到其适用性和最终效果，故不在这里进行讨论。

\subsection{神经网络在命名实体识别上的应用现状}
近年来随着计算技术和计算机硬件的发展，基于神经网络的各种深度学习方法所需要的庞大计算量渐渐能够得到满足，深度学习方法在命名实体识别任务上的应用得到了广泛的研究，并取得了令人瞩目的成果。

目前，基于深度学习的方法在命名实体识别任务上的主要应用大多采用对序列输入有一定适应性的神经网络结构进行，如循环神经网络（Recurrent Neural Network，RNN）和能够很好获取局部特征信息的卷积神经网络（Convolution Neural Network，CNN）。

\citet{collobert2011natural}提出了一个基于神经网络的框架用于对文本序列的词性标注、分块、命名实体识别和角色语义标注。
这一框架通过两种方法实现了词的one-hot向量到包含特征信息的高维特征实向量的转化，即词嵌入（word embedding）:一是基于词的上下文窗口的window approach；二是从句子层面考虑，增加了CNN层进行全局特征的提取。
该方法还能够整合多种不同的离散特征，使一个词向量能够表示的信息更加丰富，利于以此作为输入特征进行序列标注。
实验表明，使用上述方法得到的预训练词向量进行命名实体识别任务均对其识别效果有较大提升。
值得注意的是，得到该结果所使用的词向量只需要大量无标签的数据即可训练获得，省去了大量构建人工特征和标注语料集的成本，并且还能够获取更多的先验知识。

上述将词的one-hot向量转化为高维实向量的词嵌入的方法，是基于词的上下文窗口的；在此之前，已有\citet{bengio2003neural}、\citet{mikolov2010recurrent}提出了从大规模语料中获得词的分布式表示的方法。Mikolov\citep{mikolov2013distributed, mikolov2013efficient}在2013年提出的word2vec得到了广泛应用。

\citet{wu2015study}使用上述两种方法获得的词向量作为特征输入层，训练了一个神经网络进行命名实体识别，在临床医学文本i2b2数据集和SemEval数据集上取得了F值82.8\%和72.1\%的成果。

\citet{huang2015bidirectional}提出使用两层结构相同、参数独立的循环神经网络分别获取文本序列上文、下文的特征，实现上即将文本序列分别正向、反向输入这两层循环神经网络，这种架构即为双向循环神经网络。实验表明，以长短时记忆(Long Short-Term Memory， LSTM)模型为单元的双向循环神经网络，结合CRF的序列标注框架Bi-LSTM-CRF在无外部特征的情况下，在CoNLL-2003数据集上F值达到了84.26\%。

随后，双向长短时记忆网络被广泛应用于命名实体识别任务上。\citet{chiu2015named}的工作在双向长短时记忆网络的基础上使用卷积神经网络同时获取词和字符级别的特征。Bi-LSTM-CNNs框架在CoNLL-2003数据集上的F值达到了91.62\%。

\citet{ma2016end}结合了Bi-LSTM、CNN和CRF，提出了新的端到端的序列标注框架应用于词性标注、命名实体识别等任务上，在CoNLL-2003数据集上得到了91.21\%的F值。

\citet{lample2016neural}还提出了通用的序列标注框架，其基于经人工标注的字符特征和预训练的词向量进行序列标注，无需依赖额外的语言知识，在英语、德语、丹麦语和西班牙语上的实验表明其结果与当前最佳结果相近，而这些结果都使用了额外的经过标注的数据。

\subsection{中文命名实体识别的难点}
相比于以英文、法文为代表的西方语言命名实体识别，中文命名实体识别研究受限于语言本身的特性，存在更为棘手的困难，主要体现在以下几个方面：
\begin{enumerate}[\indent(1)]
    \item 中文文本中词的概念模糊，词边界难以确定。
        实际上，这一困难也是另一个序列标注的基本任务：中文分词的难点。
        汉语以字为基本单位的语言特征同大部分西文以词为基本单位的特征存在差异。
        西方语言以屈折语为主，屈折语文本中词与词之间带空格等明显表示单词界限的标志；
        而以汉语为代表的（还包括日语、藏语等）亚洲语言属于分析语或黏着语，它们通过词序与虚词的增减表达语法意义，即不存在词的格之分；
        并且就汉语本身而言，“词”的概念一直也没有一个公认的标准，对词语的切分标准也因人而异。换言之，就何为“词”而言，众多以中文为母语的使用者尚不能得到定论，遑论追求标准化、自动化的机器。
    \item 中文文本表征的信息密度较大，但显现在字型、词形上的信息较少。
        除了词边界较为明显，多数西方语言中还存在性、数、格和字母大小写等比词粒度更小的词缀特征。
        如英文存在名词的单复数变化，人名、地名和机构名一般首字母大写，缩写一般有固定的形式如联邦调查局“F.B.I.”等。
        又如以法语为代表的拉丁语系存在名词、动词和形容词等的阴性、阳性之分。
        并且西方文字中也存在大量能够表征词性、时态和词义的词根和词缀，这些信息对准确识别命名实体也起着至关重要的作用。
    \item 中文命名实体存在大量同音异字、缩略语等情况。
        中文汉字多音字、同音异字的情况多不胜数，如相同的英文人名“Kelly”可以译为“凯丽”、“凯利”、“凯莉”等；或如“西工大”、“美领馆”等组织机构名与地名存在大量简称的情况，这些与分词标注类似同样没有一套既定标准与规则的语言习惯，为中文命名实体识别增加了不少难度。
    \item 未登录词和舶来词等对命名实体形成、演变的影响。
        近年来，随着社交网络、聚合阅读与电子商务的蓬勃发展，汉语的语言结构和大众的语言习惯都悄然发生了一些变化。
        受到网络语言与外来词汇短小精悍、表意生动贴切特点的影响，汉语也正回归作为信息载体的基本属性而向着能够高效传递信息的方向发展。
        无疑，作为命名实体识别等自然语言处理任务实证的对象与应用需求的来源，汉语的发展也应作为中文自然语言处理应该考虑的一个问题，并在实际的任务场景中作出适应性的调整。
\end{enumerate}
\section{主要研究内容与文章结构}
本文在总结现有传统的基于统计机器学习的命名实体识别方法的基础上，探讨了基于神经网络的方法在中文命名实体识别任务上的应用，并针对两种不同的任务场景，分别提出了改进方法。
主要工作描述如下：
\begin{enumerate}[\indent(1)]
    \item 总结常见的基于统计的命名实体识别方法，分析比较不同方法之间的原理差异，详细介绍了基于神经网络的命名实体识别方法，指出了其相较于传统方法之间的优势
    \item 针对基于神经网络的命名实体识别方法在文言文语料上的应用进行了探讨，在给定的应用场景下进行了实验，并给出了优化方法
    \item 分别探讨了使用字、词向量进行命名实体识别的局限性，并提出了结合字词向量进行命名实体识别的方法
    \item 通过实验证明了文中提出的各改进方法的有效性，并分析方法可用的场景
\end{enumerate}

本文各章的内容安排如下：

第一章介绍了本文的选题背景和研究意义，命名实体识别与自然语言处理的关系、研究现状和文章内容结构。

第二章介绍了传统的基于统计的方法的技术原理，分析比较它们在命名实体识别任务上的性能和优缺点。

第三章介绍了基于神经网络的序列标注框架及其各部分的原理，包括字、词嵌入，循环神经网络与长短时记忆网络，在中医领域的医案文言文本上进行了命名实体识别实验，并给出了优化方法。

第四章针对一般语料上的命名实体识别任务，提出了结合字词向量的命名实体识别方法，通过实验对比了不同嵌入粒度和特征在公共领域语料集上对命名实体识别效果的影响，验证其有效性。

第五章对全文工作进行了总结，针对现有方法与文中所做研究的局限性与不足之处，指出了下一步的工作方向。
