\chapter{传统的基于统计的命名实体识别方法综述}
本章从语言模型入手，介绍了当前常见的几种基于统计的命名实体识别方法，包括以马尔可夫模型为基础的隐马尔科夫模型、结合了最大熵模型的最大熵马尔可夫模型，将命名实体识别任务转化为文本分类问题的支持向量机与决策树方法，以及目前工业界最常用，并且具有很好效果的条件随机场方法。
最后，我们通过比较这几种方法的原理和在命名实体识别任务上的性能，分析了传统的基于统计的命名实体识别方法的局限性；
同时，针对二元语言模型、隐马尔可夫模型，探讨了它们对基于神经网络的方法存在的潜在改进思路；
最后，针对条件随机场模型，探讨了其与神经网络相结合的原理和意义。
\section{隐马尔可夫模型与最大熵马尔可夫模型}
隐马尔可夫模型（hidden Markov model, HMM)和结合了最大熵方法的最大熵马尔可夫模型（maximum-entropy Markov model, MEMM）在解决序列标注问题得到了被广泛应用，其中隐马尔可夫模型还在语音识别、统计机器翻译上有着重要的应用。
\subsection{预备知识}
在介绍上述两种模型之前，需要先对n元语言模型和一般的马尔可夫模型做简要的介绍。
\subsubsection{n元语言模型}
语言模型是一种构建简单、直接的模型，是人们对语言这一抽象概念的一种相对简单的数学形式化。
语言模型实际上是针对特定语料集的统计特征建立的模型。
一般来说，对于给定的文本序列
\begin{equation}
    S = w_1 w_2 w_3 \dots w_n
\end{equation}
在语言模型下，该文本序列可判定为句子的概率$P(S)$即为模型的输出，其中$w_i, i\in \{1,2,\dots,n\}$称为文本序列的基本元素，基本元素可以是字，典型的如中文、日文等；也可以是词，如英文、法文等西方语言，也可以是其他人为规定的文本元素。
概率$P(S)$可由下式计算：
\begin{align}
    \label{eq: language model} P(S) &= P(w_1)P(w_2 | w_1)P(w_3 | w_1 w_2)\cdots P(w_n | w_1 w_2 \cdots w_{n-1})\\
    &= \prod_{i=1}^{n}P(w_i | w_1 \cdots w_{i-1})
\end{align}
可以看出，计算第$i$个基本元素出现的条件概率
\subsection{隐马尔科夫模型}
\subsection{最大熵马尔可夫模型}

\section{支持向量机与决策树}
\subsection{支持向量机}
\subsection{决策树}


\section{条件随机场}
\section{基于统计语言模型方法的比较和分析}
\section{本章小结}
